input {
  gelf {
    host => "0.0.0.0"
    port => 12201
    add_field => { "service" => "wonder" }
  }
}

filter {
  mutate {
    rename => {
      "short_message" => "message"
    }
    remove_field => ["@version", "_score"]
  }

  # Parse JSON logs and extract structured fields
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed_json"
    }

    # Extract fields from parsed JSON
    if [parsed_json][trace_id] {
      mutate {
        add_field => { "trace_id" => "%{[parsed_json][trace_id]}" }
      }
    }

    if [parsed_json][component] {
      mutate {
        add_field => { "component" => "%{[parsed_json][component]}" }
      }
    }

    if [parsed_json][layer] {
      mutate {
        add_field => { "layer" => "%{[parsed_json][layer]}" }
      }
    }

    if [parsed_json][user_id] {
      mutate {
        add_field => { "user_id" => "%{[parsed_json][user_id]}" }
      }
    }

    if [parsed_json][email] {
      mutate {
        add_field => { "email" => "%{[parsed_json][email]}" }
      }
    }

    # Replace message with the parsed message content
    if [parsed_json][message] {
      mutate {
        replace => { "message" => "%{[parsed_json][message]}" }
      }
    }

    # Remove the temporary parsed_json field
    mutate {
      remove_field => ["parsed_json"]
    }

    # Add a field to identify this as a structured log
    mutate {
      add_field => { "log_type" => "structured" }
    }
  } else {
    # Mark non-JSON logs as access logs
    mutate {
      add_field => { "log_type" => "access" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "wonder-logs-%{+YYYY.MM.dd}"
  }
  stdout {
    codec => rubydebug
  }
}
